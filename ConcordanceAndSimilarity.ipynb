{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment # 1 $My First Encounter with Linguistics!$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitted by : $Faisal Maqbool$ , Roll #: $MSDS17027$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdb\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the corpus is a list containing tokens of the document or text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordanceCorpus = ['This','is','a','cat','.','This','is','a','mat','.','This','is',\n",
    "'a','mouse','.','This','is','a','ball','.','That','is','my','cat','and','I','like','her',\n",
    "'very','much']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(word,window):\n",
    "    #Getting the indexes of the word where word found in list of tokens then extract the before and after words as per window\n",
    "    \n",
    "    indexes = [index for index,value in enumerate(concordanceCorpus) if word == value]\n",
    "    for index in indexes:\n",
    "        \n",
    "        #Subtract the window size from index but not less than 0th index and add window size to index to get the required output\n",
    "        \n",
    "        previous_index = max(index - window,0)  #to get not less than 0th index\n",
    "        after_index = index + window + 1        #adding 1 as starting index = 0\n",
    "        output_list = concordanceCorpus[previous_index:after_index]\n",
    "        #flat.append(output_list)\n",
    "        #printing every sublist as output\n",
    "        print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'cat', '.', 'This', 'is', 'a', 'mat', '.', 'This', 'is', 'a']\n",
      "['.', 'This', 'is', 'a', 'ball', '.', 'That', 'is', 'my', 'cat', 'and', 'I', 'like', 'her', 'very', 'much']\n"
     ]
    }
   ],
   "source": [
    "concordance('cat',9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarCorpus = ['A','cat','was','sleeping','.','A','wolf','was','running','.',\n",
    "                 'A','parrot','was','chirping','.','A','lion','was','roaring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Similar = []\n",
    "def similar(word,window):\n",
    "    #Getting the indexes of the word where word found in list of tokens then extract the before and after words as per window\n",
    "    indexes = [index for index,value in enumerate(similarCorpus) if word == value]\n",
    "    for index in indexes:\n",
    "        \n",
    "        #Subtract the window size from index but not less than 0th index and add window size to index to get the required output\n",
    "        \n",
    "        previous_index = max(index - window,0)  #to get not less than 0th index\n",
    "        after_index = index + window + 1        #adding 1 as starting index = 0\n",
    "        before = similarCorpus[previous_index:index]   #Backward window\n",
    "        after = similarCorpus[index+1:after_index]     #forward window\n",
    "        \n",
    "        output_list = similarCorpus[previous_index:after_index]\n",
    "        #print(before,after,output_list)\n",
    "        \n",
    "        # Now loop through every token\n",
    "        #pdb.set_trace()\n",
    "        for token in similarCorpus:\n",
    "            if token != word:\n",
    "                token_indexes = [index for index,value in enumerate(similarCorpus) if token == value]\n",
    "                \n",
    "                for token_index in token_indexes:\n",
    "                    previous_token_index = max(token_index - window,0)  #to get not less than 0th index\n",
    "                    after_token_index = token_index + window + 1        #adding 1 as starting index = 0\n",
    "                    before_token = similarCorpus[previous_token_index:token_index]   #Backward window\n",
    "                    #print(before_token)\n",
    "                    after_token = similarCorpus[token_index+1:after_token_index]\n",
    "                    #print(after_token)\n",
    "                    #Check if given word and token has similar context then add to Similar list\n",
    "                    \n",
    "                    if (before_token == before and after_token == after):\n",
    "                        Similar.append(token)\n",
    "    \n",
    "    print(Similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wolf', 'parrot', 'lion']\n"
     ]
    }
   ],
   "source": [
    "similar('cat',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 3 (a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate similar without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarWithoutContextCorpus = ['A','little','mouse','was','being','chased','by','a','cat',',','who','we','bought',\n",
    "                               'yesterday','who','was','grey','.','There','was','a','wolf','who','was','running','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarWithoutContextCorpus = [x.lower() for x in similarWithoutContextCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimilarWithoutContext = []\n",
    "def approxSimilarWithoutContext(word,window,count):\n",
    "    #Getting the indexes of the word where word found in list of tokens then extract the before and after words as per window\n",
    "    indexes = [index for index,value in enumerate(similarWithoutContextCorpus) if word == value]\n",
    "    for index in indexes:\n",
    "        \n",
    "        #Subtract the window size from index but not less than 0th index and add window size to index to get the required output\n",
    "        \n",
    "        previous_index = max(index - window,0)  #to get not less than 0th index\n",
    "        after_index = index + window + 1        #adding 1 as starting index = 0\n",
    "        before = similarWithoutContextCorpus[previous_index:index]   #Backward window\n",
    "        after = similarWithoutContextCorpus[index+1:after_index]     #forward window\n",
    "        \n",
    "        output_list = similarWithoutContextCorpus[previous_index:after_index]\n",
    "        #print(before,after,output_list)\n",
    "        \n",
    "        # Now loop through every token\n",
    "        #pdb.set_trace()\n",
    "        for token in similarWithoutContextCorpus:\n",
    "            if token != word:\n",
    "                token_indexes = [index for index,value in enumerate(similarWithoutContextCorpus) if token == value]\n",
    "                #pdb.set_trace()\n",
    "                for token_index in token_indexes:\n",
    "                    previous_token_index = max(token_index - count,0)  #to get not less than 0th index\n",
    "                    after_token_index = token_index + count + 1        #adding 1 as starting index = 0\n",
    "                    before_token = similarWithoutContextCorpus[previous_token_index:token_index]   #Backward window\n",
    "                    #print(token)\n",
    "                    #print(before_token)\n",
    "                    after_token = similarWithoutContextCorpus[token_index+1:after_token_index]\n",
    "                    #print(after_token)\n",
    "                    #print('........')\n",
    "                    \n",
    "                    #Check if given word and token has similar context then add to Similar list\n",
    "                    #pdb.set_trace()\n",
    "                    if (set(before_token).issubset(set(before)) == True and set(after_token).issubset(set(after)) == True):\n",
    "                        SimilarWithoutContext.append(token)\n",
    "                        #print(SimilarWithoutContext)\n",
    "    \n",
    "    print(SimilarWithoutContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "approxSimilarWithoutContext('cat',6,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 3 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Similar with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarWithContextCorpus = ['A','little','grey','cat','who','wasnâ€™t','sleeping',',',\n",
    "                            'but','was','eating','.','A','grey','wolf','who','was','running','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the True Negetive case\n",
    "similarWithContextCorpus = ['A','little','mouse','was','being','chased','by','a','cat',',','who','we',\n",
    "                            'bought','yesterday','who','was','grey','.','There','was','a','wolf','who','was','running','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarWithContextCorpus = [x.lower() for x in similarWithContextCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimilarWithContext = []\n",
    "def approxSimilarWithContext(word,window,count):\n",
    "    #Getting the indexes of the word where word found in list of tokens then extract the before and after words as per window\n",
    "    indexes = [index for index,value in enumerate(similarWithContextCorpus) if word == value]\n",
    "    for index in indexes:\n",
    "        \n",
    "        #Subtract the window size from index but not less than 0th index and add window size to index to get the required output\n",
    "        \n",
    "        previous_index = max(index - window,0)  #to get not less than 0th index\n",
    "        after_index = index + window + 1        #adding 1 as starting index = 0\n",
    "        before = similarWithContextCorpus[previous_index:index]   #Backward window\n",
    "        after = similarWithContextCorpus[index+1:after_index]     #forward window\n",
    "        \n",
    "        output_list = similarWithContextCorpus[previous_index:after_index]\n",
    "        #print(before,after,output_list)\n",
    "        \n",
    "        # Now loop through every token\n",
    "        #pdb.set_trace()\n",
    "        for token in similarWithContextCorpus:\n",
    "            if token != word:\n",
    "                token_indexes = [index for index,value in enumerate(similarWithContextCorpus) if token == value]\n",
    "                #pdb.set_trace()\n",
    "                for token_index in token_indexes:\n",
    "                    previous_token_index = max(token_index - count,0)  #to get not less than 0th index\n",
    "                    after_token_index = token_index + count + 1        #adding 1 as starting index = 0\n",
    "                    before_token = similarWithContextCorpus[previous_token_index:token_index]   #Backward window\n",
    "                        \n",
    "                    after_token = similarWithContextCorpus[token_index+1:after_token_index]\n",
    "                \n",
    "                    #Check if given word and token has similar context then add to Similar list\n",
    "                    #pdb.set_trace()\n",
    "                    if (set(before_token).issubset(set(before)) == True and set(after_token).issubset(set(after)) == True):\n",
    "                        #beforetoken_indexes = [list(set(before_token)).index(x) for x in before_token]\n",
    "                        #aftertoken_indexes = [list(set(after_token)).index(x) for x in after_token]\n",
    "                        #before_indexes = [list(set(before)).index(x) for x in before]\n",
    "                        #after_indexes = [list(set(after)).index(x) for x in after]\n",
    "                        \n",
    "                        #Checking the order\n",
    "                        \n",
    "                        before_token_indexes = [before.index(x) for x in before_token]\n",
    "                        after_token_indexes = [after.index(x) for x in after_token]\n",
    "                        \n",
    "                        \n",
    "                        #print (before_token_indexes, after_token_indexes)\n",
    "                        if (sorted(before_token_indexes) == before_token_indexes and sorted(after_token_indexes) == after_token_indexes):\n",
    "                            SimilarWithContext.append(token)\n",
    "                        \n",
    "                        #print(SimilarWithoutContext)\n",
    "    \n",
    "    print(SimilarWithContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wolf']\n"
     ]
    }
   ],
   "source": [
    "approxSimilarWithContext('cat',6,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
